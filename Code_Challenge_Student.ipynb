{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_Challenge_Student.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Bootcamp Selection Challenge\n",
        "#####In this challenge you will calculate various KPIs using a car based dataset, each question will have a single correct answer that will be evaluated through automated unit testing. Use the dictionary provided below to fill in your answers, each question will state the format required for the answer and examples are provided so you know how properly fill the answer dictionary. \n",
        "#####**Use the dataset \"as is\" and do not perform any data cleaning or modify it in any way, doing so could make you answer all your questions incorrectly. Do not modify the structure of the answer dictionary.**\n",
        "\n",
        "#####When you finish this challenge please upload both your notebook and your answer dictionary in pickle format to a public github repository submit their URL to the [google form](https://forms.gle/wWysZEMkoZsjB11Y7) that was provided to you.\n",
        "\n",
        "##### Some unit tests are provided at the end of this notebook to help you verify your answers are in the correct format, however they will not test everything.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ab6tQ8XLwqzG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1kj3oTmRvWXi"
      },
      "outputs": [],
      "source": [
        "#Use this dictionary to store your answers in the correct format in the cells below , do not modify the keys\n",
        "answer_dict =  {\"Q1\" : None,\n",
        "                \"Q2\" : None,\n",
        "                \"Q3\" : None,\n",
        "                \"Q4\" : None,\n",
        "                \"Q5\" : None,\n",
        "                \"Q6\" : None,\n",
        "                \"Q7\" : None}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Reading the dataset\n",
        "#####An example is provided to read the dataset using [pandas](https://pandas.pydata.org/), while we reccommend using pandas you may use any python library to solve this challenge. "
      ],
      "metadata": {
        "id": "Z0pZ4Vlx3VZy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "url='https://drive.google.com/file/d/1PCJ7ltluquoXKi6MYTPMfwZQNI_-MIFP/view?usp=sharing'\n",
        "url='https://drive.google.com/uc?id=' + url.split('/')[-2]\n",
        "df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "7U3UNKSj3oxa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "J10uW58Qv2B_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LutcGEx8v4GY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q1. What is the average CO2 emmission per gram/mile of all Volkswagen cars?\n",
        "\n",
        "##### Format: A floating number\n",
        "##### Example answer:\n",
        " `11.547`"
      ],
      "metadata": {
        "id": "kLRp8K_wnEJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q1\n",
        "#Your code here\n",
        "\n",
        "#Example answer:\n",
        "#answer_dict[\"Q1\"] =  11.547"
      ],
      "metadata": {
        "id": "jBGXf7RRnEoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q2. Calculate the top 5 brands(Make) with the most unique models, order your answer in descending order with respect to the number of unique models.\n",
        "##### **NOTE:** Consider only the name of the models and their brand, that is use only the Make and Model columns\n",
        "##### Format: A 5X2 list with each row being the name of the brand followed by the unique number of models, in descending order.\n",
        "#####Hint: You can use the pandas [df.values.tolist()](https://pandas.pydata.org/docs/reference/api/pandas.Series.tolist.html) function to format your answer.\n",
        "\n",
        "##### Example answer: \n",
        "`[[\"Volkswagen\", 1000], [\"Toyota\", 900], [\"Honda\", 800], [\"Subaru\", 700], [\"Ford\", 600]]`"
      ],
      "metadata": {
        "id": "SPNq7yn74kjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q2\n",
        "#Your code here\n",
        "\n",
        "#Example answer:\n",
        "#answer_dict[\"Q2\"] =  [[\"Volkswagen\", 1000], [\"Toyota\", 900], [\"Honda\", 800], [\"Subaru\", 700], [\"Ford\", 600]] "
      ],
      "metadata": {
        "id": "StipyFue4Dx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q3. What are all the different types of fuels in the dataset sorted alphabetically?\n",
        "##### Format: A list of strings sorted alphabetically.\n",
        "##### Example Answer: \n",
        "`['Regular',\n",
        " 'Premium']`"
      ],
      "metadata": {
        "id": "EGxv7N15AiLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q3\n",
        "#Your code here\n",
        "\n",
        "#Example answer:\n",
        "#answer_dict[\"Q3\"] =  ['Regular', 'Premium'] "
      ],
      "metadata": {
        "id": "otyDsWpsAjde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q4. Show the 9 Toyota cars with the most extreme Fuel Barrels/Year in abosolute terms within all Toyota cars. Show the car Model, Year and their Fuel Barrels/Year in standard deviation units([Z-score](https://fredclavel.org/2019/03/18/basics-standardization-and-the-z-score/)) **sorted** in descending order by their Fuel Barrels/Year in absolute terms first and then by year in descending order **BUT** without modifying the negative values (see example).\n",
        "\n",
        "##### Format: A 9X3 list with each row containing the Model, Year and Fuel Barrels/Year in standard deviations units\n",
        "\n",
        "##### Example answer: \n",
        "```\n",
        "[['DJ Po Vehicle 2WD', 2004, -6.407431084026927],\n",
        " ['FJ8c Post Office', 2003, -6.407431084026927],\n",
        " ['Post Office DJ5 2WD', 2005, -6.391684618442447],\n",
        " ['Sierra 2500 Hd 2WD', 2002, -6.391684618442447],\n",
        " ['Camry CNG', 2012, 2.677633075759575],\n",
        " ['Sierra 1500 4WD', 2005, 2.677633075759575],\n",
        " ['Sierra 1500 4WD', 2001, 2.677633075759575],\n",
        " ['V15 Suburban 4WD', 1988, 2.677633075759575],\n",
        " ['V15 Suburban 4WD', 1987, 2.677633075759575]]\n",
        "```\n",
        "#####Note that while the list is sorted by the Fuel Barrels/Year in absolute terms and in standard deviation units, the values are not modified. If the values are the same the rows are sorted by the year.\n"
      ],
      "metadata": {
        "id": "ijpZht03tV5W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q4\n",
        "#Your code here\n"
      ],
      "metadata": {
        "id": "de_GgmrFVcvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q5. Calculate the changes in Combined MPG with their previous model of all Golf cars with Manual 5-spd transmission and Regular Fuel Type. Show the Year, the Combined MPG and the calculated difference of MPG in a list sorted by Year in ascending order.\n",
        "\n",
        "##### Format: A 19X3 list, with the Year and Combined MPG being of type integer **and only the calculated difference is of type float**\n",
        "##### **Note: The value for the first model should be 0.** It does not matter that there are gaps in the years, calculate with respect the previous model.\n",
        "\n",
        "#####Example answer:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "[[1986, 25, 0.0],\n",
        " [1987, 25, 0.0],\n",
        " [1988, 25, 0.0],\n",
        " [1989, 25, 0.0],\n",
        " [1990, 23, -2.0],\n",
        " [1991, 23, 0.0],\n",
        " [1992, 24, 1.0],\n",
        " [1993, 25, 1.0],\n",
        " [1994, 25, 0.0],\n",
        " [1995, 25, 0.0],\n",
        " [1996, 25, 0.0],\n",
        " [1997, 25, 0.0],\n",
        " [1998, 24, -1.0],\n",
        " [1999, 25, 1.0],\n",
        " [2000, 24, -1.0],\n",
        " [2001, 24, 0.0],\n",
        " [2002, 24, 0.0],\n",
        " [2004, 24, 0.0],\n",
        " [2006, 24, 0.0]]\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7eCpEljJnXzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q5\n",
        "#Your code here\n"
      ],
      "metadata": {
        "id": "lMlKfEWUH3S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q6. What are the top 5 lowest CO2 Emission Grams/Mile emmisions of cars for each of the following brands: Toyota, Ford, Volkswagen, Nissan, Honda\n",
        "\n",
        "#####Format: A 5X6 list with the first element of each row being the Make of the cars and the following five values being floats sorted in ascending order. The Makes should appear in order listed in the question starting with Toyota and ending with Honda (see example).\n",
        "\n",
        "#####Example answer:\n",
        "\n",
        "```\n",
        "[['Toyota', 100.0, 140.0, 140.0, 150.0, 150.0],\n",
        " ['Ford',\n",
        "  100.025641025641,\n",
        "  200.677633075759575,\n",
        "  200.677633075759575,\n",
        "  200.677633075759575,\n",
        "  200.677633075759575],\n",
        " ['Volkswagen', 139.0, 154.0, 166.5, 166.5, 166.5],\n",
        " ['Nissan', 122.0, 122.0, 122.0, 122.0, 160.0],\n",
        " ['Honda', 100.0, 100.0, 100.0, 100.0, 123.91684618442447]]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EnHdqUs-nagE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q6\n",
        "#Your code here\n"
      ],
      "metadata": {
        "id": "8KKg3bT6na41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Q7. Form 7 groups of 5 years to calculated the median Combined MPG of each group. The first group is from 1984 to 1988, the second from 1989 to 1993 and so on. The last group will have years not appearing in the dataset.\n",
        "\n",
        "#####Note: The groups ranges are inclusive on both sides, the first group starts with 1984 and cars from 1984 are included in it.\n",
        "#####Format : A 7X2 list with the first element of each row being a tuple of two integers being the lower and uppper range of the year groups and the esecond element being the median Combined MPG of that group, a float number.\n",
        "\n",
        "#####Example answer:\n",
        "\n",
        "\n",
        "```\n",
        "[[(1984, 1988), 11.0],\n",
        " [(1989, 1993), 10.0],\n",
        " [(1994, 1998), 10.0],\n",
        " [(1999, 2003), 14.0],\n",
        " [(2004, 2008), 13.0],\n",
        " [(2009, 2013), 14.0],\n",
        " [(2014, 2018), 15.0]]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "gDNo1Fcesgk5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "########## Q7\n",
        "#Your code here\n"
      ],
      "metadata": {
        "id": "1cMEyFXVxBU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Test your answers\n",
        "\n",
        "##### We provide you some tests to make sure your answer dictionary is in the correct format using unittest.\n",
        "##### These tests are not meant to be comprehensive, you should review all your answers carefully."
      ],
      "metadata": {
        "id": "LiGydnlQ4cX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestAnswers(unittest.TestCase):\n",
        "    def test_if_dict(self):\n",
        "        self.assertIsInstance(answer_dict, dict)\n",
        "\n",
        "    def test_keys(self):\n",
        "        self.assertEqual(list(answer_dict.keys()), ['Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7'])\n",
        "\n",
        "    def test_answers_types(self):\n",
        "        types_values = [type(k) for k in answer_dict.values()]\n",
        "        answer_types = [float, list, list, list, list, list, list]\n",
        "        self.assertEqual(types_values, answer_types)\n",
        "\n",
        "    def test_Q1(self):\n",
        "        self.assertEqual(type(answer_dict['Q1']), float)\n",
        "\n",
        "    def test_Q2_dim(self):\n",
        "        self.assertEqual(np.array(answer_dict['Q2']).shape, (5,2))\n",
        "\n",
        "    def test_Q2_types(self):\n",
        "        dtype1 = type(answer_dict['Q2'][0][0])\n",
        "        dtype2 = type(answer_dict['Q2'][0][1])\n",
        "        self.assertEqual([dtype1, dtype2], [str, int])\n",
        "\n",
        "    def test_Q3_types(self):\n",
        "        q3_types = set([type(item) for item in answer_dict['Q3']])\n",
        "        self.assertEqual(q3_types, {str})\n",
        "\n",
        "    def test_Q4_dim(self):\n",
        "        self.assertEqual(np.array(answer_dict['Q4']).shape, (9,3))\n",
        "\n",
        "    def test_Q4_types(self):\n",
        "        dtype1 = type(answer_dict['Q4'][0][0])\n",
        "        dtype2 = type(answer_dict['Q4'][0][1])\n",
        "        dtype3 = type(answer_dict['Q4'][0][2])\n",
        "        self.assertEqual([dtype1, dtype2, dtype3], [str, int, float])\n",
        "\n",
        "    def test_Q5_dim(self):\n",
        "        self.assertEqual(np.array(answer_dict['Q5']).shape, (19,3))\n",
        "\n",
        "    def test_Q5_types(self):\n",
        "        dtype1 = type(answer_dict['Q5'][0][0])\n",
        "        dtype2 = type(answer_dict['Q5'][0][1])\n",
        "        dtype3 = type(answer_dict['Q5'][0][2])\n",
        "        self.assertEqual([dtype1, dtype2, dtype3], [int, int, float])\n",
        "\n",
        "    def test_Q5_first_zero(self):\n",
        "        self.assertEqual(answer_dict['Q5'][0][2], 0)\n",
        "\n",
        "\n",
        "    def test_Q6_dim(self):\n",
        "        self.assertEqual(np.array(answer_dict['Q6']).shape, (5,6))\n",
        "\n",
        "    def test_Q5_types(self):\n",
        "        dtype1 = type(answer_dict['Q6'][0][0])\n",
        "        dtype2 = type(answer_dict['Q6'][0][1])\n",
        "        dtype3 = type(answer_dict['Q6'][0][2])\n",
        "        dtype4 = type(answer_dict['Q6'][0][3])\n",
        "        dtype5 = type(answer_dict['Q6'][0][4])\n",
        "        dtype6 = type(answer_dict['Q6'][0][5])\n",
        "        self.assertEqual([dtype1, dtype2, dtype3, dtype4, dtype5, dtype6], [str, float, float, float, float, float])\n",
        "\n",
        "    def test_Q6_check_first_and_last_brand(self):\n",
        "        first_brand = answer_dict['Q6'][0][0]\n",
        "        last_brand = answer_dict['Q6'][4][0]\n",
        "\n",
        "        self.assertEqual([first_brand, last_brand], [\"Toyota\", \"Honda\"])\n",
        "\n",
        "    def test_Q7_dim(self):\n",
        "        self.assertEqual(np.array(answer_dict['Q7'], dtype=object).shape, (7,2))\n",
        "\n",
        "    def test_Q7_types(self):\n",
        "        dtype1 = type(answer_dict['Q7'][0][0])\n",
        "        dtype2 = type(answer_dict['Q7'][0][1])\n",
        "        self.assertEqual([dtype1, dtype2], [tuple, float])\n",
        "\n",
        "unittest.main(argv=[''], verbosity=2, exit=False)"
      ],
      "metadata": {
        "id": "iNwVFmHZ4csn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save your answers\n",
        "\n",
        "\n",
        "##### First, take a moment to evaluate your answers and make sure you have not missed anything\n",
        "\n",
        "##### Use the following code to save your answers in pickle format, change the filename using the following format:\n",
        "##### FIRSTNAME_LASTNAME_answers.pkl\n",
        "##### Example: Juan_Perez_answers.pkl\n",
        "\n",
        "##### If you are using google colab you can find your file on the left side bar by clicking the folder icon inside the sample_data folder. Remember to upload the pickle file and the notebook to github and submit their URLs to the [google form](https://forms.gle/wWysZEMkoZsjB11Y7)."
      ],
      "metadata": {
        "id": "O_Wx_D0kGjmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "answer_dict"
      ],
      "metadata": {
        "id": "nCzU1sKMknfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "file_name = \"FIRSTNAME_LASTNAME_answers.pkl\"\n",
        "path = \"\"\n",
        "\n",
        "with open(path+file_name, 'wb') as f:\n",
        "    pickle.dump(answer_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "dEZ-vo0QGTeu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}